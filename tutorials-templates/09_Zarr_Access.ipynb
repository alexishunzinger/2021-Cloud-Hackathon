{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 09. Zarr Access for NetCDF4 files"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Timing:\n",
        "- Exercise: 45 minutes\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Zarr is an open source library for storing N-dimensional array data.  It supports multidimensional arrays with attributes and dimensions similar to NetCDF4, and it can be read by XArray.  Zarr is often used for data held in cloud object storage (like Amazon S3), because it is better optimized for these situations than NetCDF4.\n",
        "\n",
        "The [zarr-eosdis-store library](https://github.com/nasa/zarr-eosdis-store) allows NASA EOSDIS NetCDF4 files to be read more efficiently by transferring only file metadata and data needed for computation in a small number of requests, rather than moving the whole file or making many small requests.  It works by making the files directly readable by the [Zarr Python library](https://zarr.readthedocs.io) and XArray across a network.  To use it, files must have a corresponding metadata file ending in `.dmrpp`, which increasingly true for cloud-accessible EOSDIS data.  https://github.com/nasa/zarr-eosdis-store\n",
        "\n",
        "The zarr-eosdis-store library provides several benefits over downloading EOSDIS data files and accessing them using XArray, NetCDF4, or HDF5 Python libraries:\n",
        "\n",
        "* It only downloads the chunks of data you actually read, so if you don't read all variables or the full spatiotemporal extent of a file, you usually won't spend time downloading those portions of the file\n",
        "* It parallelizes and optimizes downloads for the portions of files you do read, so download speeds can be faster in general\n",
        "* It automatically interoperates with Earthdata Login if you have a .netrc file set up\n",
        "* It is aware of some EOSDIS cloud implementation quirks and provides caching that can save time for repeated requests to individual files\n",
        "\n",
        "It can also be faster than using XArray pointing NetCDF4 files with s3:// URLs, depending on the file's internal structure, and is often more convenient.\n",
        "\n",
        "Consider using this library when:\n",
        "1. The portion of the data file you need to use is much smaller than the full file, e.g. in cases of spatial subsets or reading a single variable from a file containing several\n",
        "1. s3:// URLs are not readily available\n",
        "1. Code need to run outside of the AWS cloud or us-west-2 region or in a hybrid cloud / non-cloud manner\n",
        "1. s3:// access using XArray seems slower than you would expect (possibly due to unoptimized internal file structure)\n",
        "1. No readily-available, public, cloud-optimized version of the data exists already. The example we show _is_ also available as an AWS Public Dataset: https://registry.opendata.aws/mur/\n",
        "1. Adding \".dmrpp\" to the end of a data URL returns a file\n",
        "\n",
        "### Objectives\n",
        "\n",
        "1. Build on prior knowledge from CMR and Earthdata Login tutorials\n",
        "2. Work through an example of using the EOSDIS Zarr Store to access data using XArray\n",
        "3. Learn about the Zarr format and library for accessing data in the cloud\n",
        "___\n",
        "\n",
        "\n",
        "## Exercise\n",
        "\n",
        "In this exercise, we will be using the eosdis-zarr-store library to aggregate and analyze a month of sea surface temperature for the Great Lakes region\n",
        "\n",
        "### Set up\n",
        "\n",
        "#### Import Required Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Also set the width / height for plots we show"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Set Dataset, Time, and Region of Interest\n",
        "\n",
        "Look in PO.DAAC's cloud archive for Group for High Resolution Sea Surface Temperature (GHRSST) Level 4 Multiscale Ultrahigh Resolution (MUR) data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looking for data from the month of September over the Great Lakes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Find URLs for the dataset and AOI\n",
        "\n",
        "Set up a CMR granules search for our area of interest, as we saw in prior tutorials"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Search for granules in our area of interest, expecting one granule per day of September"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Open and view our AOI without downloading a whole file\n",
        "\n",
        "#### Check to see if we can use an efficient partial-access technique"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Open our first URL using the Zarr library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That's it!  No downloads, temporary credentials, or S3 filesystems.  Hereafter, we interact with the `ds` variable as with any XArray dataset.  We need not worry about the EosdisStore anymore.\n",
        "\n",
        "View the file's variable structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Aggregate and analyze 30 files\n",
        "\n",
        "Set up a function to open all of our URLs as XArrays in parallel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Combine the individual file-based datasets into a single xarray dataset with a time axis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Look at the Analysed SST variable metadata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a dataset / variable that is only our area of interest and view its metadata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "XArray reads data lazily, i.e. only when our code actually needs it.  Up to this point, we haven't read any data values, only metadata.  The next line will force XArray to read the portions of the source files containing our area of interest.  Behind the scenes, the eosdis-zarr-store library is ensuring data is fetched as efficiently as possible.\n",
        "\n",
        "Note: This line isn't strictly necessary, since XArray will automatically read the data we need the first time our code tries to use it, but calling this will make sure that we can read the data multiple times later on without re-fetching anything from the source files.\n",
        "\n",
        "This line will take several seconds to complete, but since it is retrieving only about 50 MB of data from 22 GB of source files, several seconds constitutes a significant time, bandwidth, and disk space savings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can start looking at aggregations across the time dimension.  In this case, plot the standard deviation of the temperature at each point to get a visual sense of how much temperatures fluctuate over the course of the month."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Interactive animation of a month of data\n",
        "\n",
        "This section isn't as important to fully understand.  It shows us a way to get an interactive animation to see what we have retrieved so far\n",
        "\n",
        "Define an animation function to plot the `i`th time step.  We need to make sure each plot is using the same color scale, set by `vmin` and `vmax` so the animation is consistent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Render each time slice once and show it as an HTML animation with interactive controls"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Supplemental: What's happening here?\n",
        "\n",
        "For EOSDIS data in the cloud, we have begun producing a metadata sidecar file in a format called DMR++ that extracts all of the information about arrays, variables, and dimensions from data files, as well as the byte offsets in the NetCDF4 file where data can be found.  This information is sufficient to let the Zarr library read data from our NetCDF4 files, but it's in the wrong format.  zarr-eosdis-store knows how to fetch the sidecar file and transform it into something the Zarr library understands.  Passing it when reading Zarr using XArray or the Zarr library lets these libraries interact with EOSDIS data exactly as if they were Zarr stores in a way that's more optimal for reading data in the cloud.  Beyond this, the zarr-eosdis-store library makes some optimizations in the way it reads data to help make up for situations where the NetCDF4 file is not internally arranged well for cloud-based access patterns.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}